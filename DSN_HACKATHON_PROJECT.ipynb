{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LadyJ101/dsn_hackathon_project/blob/main/DSN_HACKATHON_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QLmqrrZaNn8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDoK2jSfUsNL",
        "outputId": "f7c60dc1-f324-4503-9d25-3c50113da618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #Mounted my google drive to this notebook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Oy4TspTfIVF"
      },
      "source": [
        "IMPORTING NECESSARY LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdXTh-cAR0GR",
        "outputId": "405a3521-b19c-4ab2-9fa5-2f71af2b55f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages with confirmation...\n"
          ]
        }
      ],
      "source": [
        "#Installing XGBoost and optuna\n",
        "print(\"Installing required packages with confirmation...\")\n",
        "\n",
        "# Install with clear output\n",
        "!pip install xgboost optuna --quiet\n",
        "\n",
        "# Verify installations\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    import optuna\n",
        "    print(\"XGBoost and Optuna installed successfully!\")\n",
        "    print(f\"XGBoost version: {xgb.__version__}\")\n",
        "except Exception as e:\n",
        "    print(f\"Installation failed: {e}\")\n",
        "    print(\"Trying alternative installation...\")\n",
        "    !pip install xgboost optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A91IacE5MHOC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd #Pandas for data manipulation\n",
        "import numpy as np #Numpy for numerical computation\n",
        "import matplotlib.pyplot as plt #Matplotlib for data visualization\n",
        "import seaborn as sns #Seaborn for data visualization\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split, KFold #To split the dataset and initialize kfold\n",
        "from sklearn.metrics import mean_squared_error #For evaluation of mean_squared error\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder #For feature encoding of categorical data\n",
        "import xgboost as xgb #Model\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8UnivSnfgTw"
      },
      "source": [
        "LOADING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3S9sy_ZffyX"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/hackathon-qualification/archive/train.csv\") #Loading the train set\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/hackathon-qualification/archive/test.csv\") #Loading the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HtYi15Afmvr"
      },
      "outputs": [],
      "source": [
        "train_df.head(15) #To check the first 15 rows of the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOEHWjgQfxFp"
      },
      "outputs": [],
      "source": [
        "test_df.head(15) #To check the first 15 rows of the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JErRS3NJf4-2"
      },
      "outputs": [],
      "source": [
        "#Check the shape of the given datasets both train and test\n",
        "print(\"Train DataFrame Shape:\", train_df.shape)\n",
        "print(\"Test DataFrame Shape:\", test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfB8HReJgu6S"
      },
      "outputs": [],
      "source": [
        "train_df.describe() #To check the mathematical features of the numerical columns in the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhVeZnmrg3dV"
      },
      "outputs": [],
      "source": [
        "test_df.describe() #To check the mathematical features of the numerical columns in the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXeb-yWdg5L8"
      },
      "outputs": [],
      "source": [
        "train_df.info() #To check the information of the columns in the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hlo_QH0fg_sX"
      },
      "outputs": [],
      "source": [
        "test_df.info() #To check the information of the columns in the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLORATORY DATA ANALYSIS"
      ],
      "metadata": {
        "id": "KDRTFBmTgisT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqDZirgWhCaA"
      },
      "outputs": [],
      "source": [
        "print(\"DATA QUALITY ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "#Missing Values Analysis\n",
        "#Missing Values Analysis I Train set\n",
        "print(\"MISSING VALUES IN TRAINING DATA:\")\n",
        "missing_train = train_df.isnull().sum()\n",
        "print(missing_train[missing_train > 0])\n",
        "\n",
        "#Missing Values Analysis in Test set\n",
        "print(\"\\n2. MISSING VALUES IN TEST DATA:\")\n",
        "missing_test = test_df.isnull().sum()\n",
        "print(missing_test[missing_test > 0])\n",
        "\n",
        "#Target Variable Analysis\n",
        "print(\"\\n3. TARGET VARIABLE 'price' ANALYSIS:\")\n",
        "print(f\"   Min price: ${train_df['price'].min():,}\")\n",
        "print(f\"   Max price: ${train_df['price'].max():,}\")\n",
        "print(f\"   Mean price: ${train_df['price'].mean():,.0f}\")\n",
        "print(f\"   Median price: ${train_df['price'].median():,.0f}\")\n",
        "\n",
        "#Unique Values in Categorical Columns\n",
        "print(\"\\n4. CATEGORICAL FEATURES UNIQUE COUNTS:\")\n",
        "categorical_cols = train_df.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    print(f\"   {col}: {train_df[col].nunique()} unique values\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA VISUALIZATION"
      ],
      "metadata": {
        "id": "ijZxR1CRhp-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set style for plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "#Histograms for numerical features\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot histogram for model_year\n",
        "sns.histplot(train_df['model_year'], bins=20, ax=axes[0])\n",
        "axes[0].set_title('Distribution of Model Year')\n",
        "\n",
        "# Plot histogram for mileage\n",
        "sns.histplot(train_df['milage'], bins=20, ax=axes[1])\n",
        "axes[1].set_title('Distribution of Milage')\n",
        "\n",
        "# Plot histogram for price\n",
        "sns.histplot(train_df['price'], bins=20, ax=axes[2])\n",
        "axes[2].set_title('Distribution of Price')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "omP51eJjhso9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scatter plots vs price\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "#Scatter: model_year vs price\n",
        "sns.scatterplot(x=train_df['model_year'], y=train_df['price'], alpha=0.5, ax=axes[0])\n",
        "axes[0].set_title('Model Year vs Price')\n",
        "\n",
        "#Scatter: mileage vs price\n",
        "sns.scatterplot(x=train_df['milage'], y=train_df['price'], alpha=0.5, ax=axes[1])\n",
        "axes[1].set_title('Milage vs Price')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "PXFCdPlOiKf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation heatmap for numerical features\n",
        "numerical_df = train_df[['model_year', 'milage', 'price']]\n",
        "corr_matrix = numerical_df.corr()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Heatmap for Numerical Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jcA9ywRjiLME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create boxplots for numerical features\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "#Boxplot for price\n",
        "sns.boxplot(y=train_df['price'], ax=axes[0])\n",
        "axes[0].set_title('Boxplot of Price')\n",
        "\n",
        "# Boxplot for mileage\n",
        "sns.boxplot(y=train_df['milage'], ax=axes[1])\n",
        "axes[1].set_title('Boxplot of Mileage')\n",
        "\n",
        "# Boxplot for model_year\n",
        "sns.boxplot(y=train_df['model_year'], ax=axes[2])\n",
        "axes[2].set_title('Boxplot of Model Year')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ammfn3ZYiP8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to detect outliers using IQR\n",
        "def count_outliers(series):\n",
        "    Q1 = series.quantile(0.25)\n",
        "    Q3 = series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = series[(series < lower_bound) | (series > upper_bound)]\n",
        "    return len(outliers)\n",
        "\n",
        "# Count outliers for price and mileage\n",
        "price_outliers = count_outliers(train_df['price'])\n",
        "milage_outliers = count_outliers(train_df['milage'])\n",
        "\n",
        "print(f\"Number of outliers in price: {price_outliers}\")\n",
        "print(f\"Number of outliers in mileage: {milage_outliers}\")"
      ],
      "metadata": {
        "id": "0kBJD1HSiS7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import skew\n",
        "\n",
        "price_skew = skew(train_df['price']) #For evaluation of skewness\n",
        "print(f\"Skewness of price after cleaning: {price_skew}\")"
      ],
      "metadata": {
        "id": "Kk1VS9aEiV1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean price for each brand\n",
        "mean_price_by_brand = train_df.groupby('brand')['price'].mean().sort_values(ascending=False)\n",
        "\n",
        "#Top 10 brands by mean price\n",
        "top10_mean_price = mean_price_by_brand.head(10)\n",
        "\n",
        "# Bar plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=top10_mean_price.index, y=top10_mean_price.values)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Top 10 Brands by Average Price')\n",
        "plt.ylabel('Average Price ($)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NYbRIPJqibp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get count and mean price for top 10 brands by count\n",
        "top10_brands_by_count = train_df['brand'].value_counts().head(10).index\n",
        "train_top10 = train_df[train_df['brand'].isin(top10_brands_by_count)]\n",
        "\n",
        "# Bar plot: mean price for top 10 brands (by count)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='brand', y='price', data=train_top10, estimator='mean')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Average Price for Top 10 Brands (by Frequency)')\n",
        "plt.ylabel('Average Price ($)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rxj4ZYL7if76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fuel_type vs mean price\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x='fuel_type', y='price', data=train_df, estimator='mean')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Average Price by Fuel Type')\n",
        "plt.show()\n",
        "\n",
        "# Accident vs mean price\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x='accident', y='price', data=train_df, estimator='mean')\n",
        "plt.title('Average Price by Accident History')\n",
        "plt.show()\n",
        "\n",
        "# Transmission vs mean price (top 10 common transmissions)\n",
        "top_transmissions = train_df['transmission'].value_counts().head(10).index\n",
        "train_top_trans = train_df[train_df['transmission'].isin(top_transmissions)]\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.barplot(x='transmission', y='price', data=train_top_trans, estimator='mean')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Average Price by Top 10 Transmissions')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gJGMn6nDiilH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA CLEANING"
      ],
      "metadata": {
        "id": "MnMF4Uyigzlp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NamWbQpDsv5B"
      },
      "outputs": [],
      "source": [
        "print(\" SMART DATA CLEANING\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "#Remove extreme price outliers (99.9th percentile)\n",
        "price_upper_limit = train_df['price'].quantile(0.999)\n",
        "train_clean = train_df[train_df['price'] <= price_upper_limit].copy()\n",
        "outliers_removed = len(train_df) - len(train_clean)\n",
        "\n",
        "print(f\"1. Removed {outliers_removed} extreme price outliers\")\n",
        "print(f\"   Price upper limit: ${price_upper_limit:,.0f}\")\n",
        "\n",
        "#Drop useless clean_title column (only 1 value)\n",
        "train_clean = train_clean.drop('clean_title', axis=1)\n",
        "test_df = test_df.drop('clean_title', axis=1)\n",
        "\n",
        "print(\"2. Dropped 'clean_title' column (only 1 unique value)\")\n",
        "\n",
        "#Handle missing values\n",
        "print(\"3. Missing values to handle later:\")\n",
        "print(f\"   - fuel_type: {train_clean['fuel_type'].isnull().sum()} missing\")\n",
        "print(f\"   - accident: {train_clean['accident'].isnull().sum()} missing\")\n",
        "\n",
        "print(f\"\\nNew training shape: {train_clean.shape}\")\n",
        "print(f\" New test shape: {test_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Strategic Missing Value Handling"
      ],
      "metadata": {
        "id": "diN6BvRIg90J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "essCzkWHs_vn"
      },
      "outputs": [],
      "source": [
        "print(\" SMART MISSING VALUE HANDLING\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "#Handle fuel_type missing values - use mode but be smart\n",
        "most_common_fuel = train_clean['fuel_type'].mode()[0]\n",
        "train_clean['fuel_type'] = train_clean['fuel_type'].fillna(most_common_fuel)\n",
        "test_df['fuel_type'] = test_df['fuel_type'].fillna(most_common_fuel)\n",
        "\n",
        "print(f\"1. Filled fuel_type missing values with: '{most_common_fuel}'\")\n",
        "\n",
        "#Handle accident missing values - use 'None reported' (most common)\n",
        "train_clean['accident'] = train_clean['accident'].fillna('None reported')\n",
        "test_df['accident'] = test_df['accident'].fillna('None reported')\n",
        "\n",
        "print(\"2. Filled accident missing values with: 'None reported'\")\n",
        "\n",
        "#Verify no more missing values\n",
        "print(\"\\n MISSING VALUES AFTER HANDLING:\")\n",
        "print(\"Training data:\")\n",
        "print(train_clean.isnull().sum())\n",
        "print(\"\\nTest data:\")\n",
        "print(test_df.isnull().sum())\n",
        "\n",
        "print(f\"\\n FINAL CLEAN DATA SHAPES:\")\n",
        "print(f\"Training: {train_clean.shape}\")\n",
        "print(f\"Test: {test_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEATURE ENCODING"
      ],
      "metadata": {
        "id": "SUoRehvEhHyp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DGH8BMrtP6i"
      },
      "outputs": [],
      "source": [
        "print(\" ADVANCED FEATURE ENGINEERING\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Create new features for both training and test data\n",
        "def create_features(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    #Car Age (current year - model_year)\n",
        "    df['car_age'] = 2025 - df['model_year']\n",
        "\n",
        "    #Mileage per Year (usage intensity)\n",
        "    df['miles_per_year'] = df['milage'] / df['car_age'].clip(lower=1)\n",
        "\n",
        "    #Luxury Brand Flag (premium brands)\n",
        "    luxury_brands = ['BMW', 'Mercedes-Benz', 'Audi', 'Lexus', 'Porsche', 'Genesis', 'Land Rover', 'Jaguar']\n",
        "    df['is_luxury'] = df['brand'].isin(luxury_brands).astype(int)\n",
        "\n",
        "    #Engine Power Extraction (if available in engine text)\n",
        "    df['has_turbo'] = df['engine'].str.contains('Turbo|Twin|Supercharger', case=False, na=False).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply to both datasets\n",
        "train_enhanced = create_features(train_clean)\n",
        "test_enhanced = create_features(test_df)\n",
        "\n",
        "print(\"CREATED POWERFUL NEW FEATURES:\")\n",
        "print(\"   - car_age (years since model year)\")\n",
        "print(\"   - miles_per_year (annual usage intensity)\")\n",
        "print(\"   - is_luxury (premium brand flag)\")\n",
        "print(\"   - has_turbo (high-performance engine flag)\")\n",
        "\n",
        "print(f\"\\n Enhanced Training Shape: {train_enhanced.shape}\")\n",
        "print(f\" Enhanced Test Shape: {test_enhanced.shape}\")\n",
        "\n",
        "print(\"\\n Sample of new features:\")\n",
        "display(train_enhanced[['brand', 'model_year', 'car_age', 'miles_per_year', 'is_luxury', 'has_turbo']].head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Prepare Data for Modeling"
      ],
      "metadata": {
        "id": "85MNfIJZhU-z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWUROfdRtgR9"
      },
      "outputs": [],
      "source": [
        "print(\" PREPARING DATA FOR MODELING\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "#Separate features (X) and target (y) for training\n",
        "X = train_enhanced.drop('price', axis=1)\n",
        "y = train_enhanced['price']\n",
        "\n",
        "print(\" FEATURES (X) and TARGET (y) separated:\")\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n",
        "\n",
        "#Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "print(f\"\\n Categorical features ({len(categorical_cols)}):\")\n",
        "print(categorical_cols)\n",
        "\n",
        "print(f\"\\n Numerical features ({len(numerical_cols)}):\")\n",
        "print(numerical_cols)\n",
        "\n",
        "print(f\"\\n New engineered features:\")\n",
        "new_features = ['car_age', 'miles_per_year', 'is_luxury', 'has_turbo']\n",
        "for feat in new_features:\n",
        "    print(f\"   - {feat}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " REMOVING PROBLEMATIC ID COLUMN & TRAINING ON FULL DATA"
      ],
      "metadata": {
        "id": "E5rqlYt2WDSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove ID column from all datasets\n",
        "X_encoded_no_id = X.drop('id', axis=1)\n",
        "test_encoded_no_id = test_df.drop('id', axis=1)\n",
        "\n",
        "print(\" ID COLUMN REMOVED!\")\n",
        "print(f\"New X shape: {X_encoded_no_id.shape}\")\n",
        "print(f\"New test shape: {test_encoded_no_id.shape}\")"
      ],
      "metadata": {
        "id": "KrESYM76WJVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ENCODE CATGORICAL FEATURES"
      ],
      "metadata": {
        "id": "XQ3DbYfaWRCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_final_clean.info()"
      ],
      "metadata": {
        "id": "9GhKIdzAaFv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REAPPLYING FEATURE ENGINEERING TO TEST DATA"
      ],
      "metadata": {
        "id": "Ga5l9LsTcGPq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwnlfSBtrnN_"
      },
      "outputs": [],
      "source": [
        "# First, let's see what columns are missing\n",
        "missing_cols = set(X_final_clean.columns) - set(test_final_clean.columns)\n",
        "print(f\"Missing columns in test data: {missing_cols}\")\n",
        "\n",
        "# Create the missing features directly without the function\n",
        "test_with_features = test_df.copy()\n",
        "\n",
        "# Add the missing engineered features\n",
        "test_with_features['car_age'] = 2025 - test_with_features['model_year']\n",
        "test_with_features['miles_per_year'] = test_with_features['milage'] / test_with_features['car_age'].clip(lower=1)\n",
        "\n",
        "# Luxury Brand Flag - we need to use the original brand names\n",
        "luxury_brands = ['BMW', 'Mercedes-Benz', 'Audi', 'Lexus', 'Porsche', 'Genesis', 'Land Rover', 'Jaguar']\n",
        "test_with_features['is_luxury'] = test_with_features['brand'].isin(luxury_brands).astype(int)\n",
        "\n",
        "# Turbo detection\n",
        "test_with_features['has_turbo'] = test_with_features['engine'].str.contains('Turbo|Twin|Supercharger', case=False, na=False).astype(int)\n",
        "\n",
        "# Now encode ALL categorical columns properly\n",
        "test_encoded_complete = test_with_features.copy()\n",
        "categorical_cols = ['brand', 'model', 'fuel_type', 'engine', 'transmission', 'ext_col', 'int_col', 'accident']\n",
        "\n",
        "print(\"Encoding categorical columns for test data...\")\n",
        "for col in categorical_cols:\n",
        "    if col in test_encoded_complete.columns and test_encoded_complete[col].dtype == 'object':\n",
        "        # Simple label encoding for test data\n",
        "        le = LabelEncoder()\n",
        "\n",
        "        # Fit on the test data (since we don't have the training encoders)\n",
        "        # This ensures all values get encoded, even if different from training\n",
        "        test_encoded_complete[col] = le.fit_transform(test_encoded_complete[col].astype(str))\n",
        "\n",
        "# Convert all to numeric and fill NaN\n",
        "for col in test_encoded_complete.columns:\n",
        "    test_encoded_complete[col] = pd.to_numeric(test_encoded_complete[col], errors='coerce')\n",
        "test_encoded_complete = test_encoded_complete.fillna(0)\n",
        "\n",
        "# Drop ID column and keep only the features used in training\n",
        "test_final_complete = test_encoded_complete.drop('id', axis=1)\n",
        "test_final_complete = test_final_complete[X_final_clean.columns]\n",
        "\n",
        "print(f\"Final test shape: {test_final_complete.shape}\")\n",
        "print(f\"Test columns: {test_final_complete.columns.tolist()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL TRAINING\n",
        "\n"
      ],
      "metadata": {
        "id": "uJBi4InFeLPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TRAINING XGBOOST MODEL ON COMPLETE DATA\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# First, train the model on your prepared training data\n",
        "xgb_model_full = xgb.XGBRegressor(\n",
        "    n_estimators=2500,\n",
        "    learning_rate=0.01,\n",
        "    max_depth=5,\n",
        "    subsample=0.6,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=0,\n",
        "    n_jobs=-1,\n",
        "    eval_metric='rmse'\n",
        ")\n",
        "\n",
        "# Train the model on your prepared training data\n",
        "xgb_model_full.fit(X_final_clean, y, verbose=50)\n",
        "\n",
        "print(\"XGBOOST MODEL TRAINING COMPLETED!\")\n",
        "\n",
        "print(\"\\nMAKING PREDICTIONS WITH ALIGNED DATA\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Now make predictions on the complete test data\n",
        "test_predictions = xgb_model_full.predict(test_final_complete)\n",
        "\n",
        "print(f\"Predictions range: ${test_predictions.min():,.2f} - ${test_predictions.max():,.2f}\")\n",
        "print(f\"Mean prediction: ${test_predictions.mean():,.2f}\")\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'price': test_predictions\n",
        "})\n",
        "\n",
        "# Ensure no negative prices\n",
        "submission['price'] = submission['price'].clip(lower=0)\n",
        "\n",
        "# Save the submission file\n",
        "submission_file = 'submission_xgboost_final.csv'\n",
        "submission.to_csv(submission_file, index=False)\n",
        "\n",
        "print(f\"Submission saved as '{submission_file}'\")\n",
        "print(f\"Submission shape: {submission.shape}\")\n",
        "print(f\"Number of predictions: {len(submission)}\")\n",
        "\n",
        "# Show sample of submission\n",
        "print(\"\\nSample of submission:\")\n",
        "print(submission.head(3))\n",
        "\n",
        "print(f\"\\n SUBMISSION SUCCESSFULLY CREATED: {submission_file}\")\n"
      ],
      "metadata": {
        "id": "zFqFzrUIjSAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RSME SCORE EVALUATION"
      ],
      "metadata": {
        "id": "BKIqm4r5fBjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate RSME\n",
        "train_rmse = np.sqrt(mean_squared_error(y, train_predictions))\n",
        "print(f\"âœ… TRAINING RMSE: ${train_rmse:,.2f}\")\n",
        "print(f\"Mean actual price: ${y.mean():,.2f}\")\n",
        "print(f\"RMSE as percentage of mean: {(train_rmse/y.mean())*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "SAbAsoq9eBdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t9G51SVUfDeW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPY/1UF2r37cIOqVF9eclPZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}