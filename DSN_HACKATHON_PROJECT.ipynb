{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LadyJ101/dsn_hackathon_project/blob/main/DSN_HACKATHON_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QLmqrrZaNn8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "nDoK2jSfUsNL",
        "outputId": "bd6d9fab-1e01-42dc-ef71-dba5d254685c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2070390110.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Mounted my google drive to this notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #Mounted my google drive to this notebook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Oy4TspTfIVF"
      },
      "source": [
        "IMPORTING NECESSARY LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdXTh-cAR0GR"
      },
      "outputs": [],
      "source": [
        "#Installing XGBoost and optuna\n",
        "print(\"Installing required packages with confirmation...\")\n",
        "\n",
        "# Install with clear output\n",
        "!pip install xgboost optuna --quiet\n",
        "\n",
        "# Verify installations\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    import optuna\n",
        "    print(\"XGBoost and Optuna installed successfully!\")\n",
        "    print(f\"XGBoost version: {xgb.__version__}\")\n",
        "except Exception as e:\n",
        "    print(f\"Installation failed: {e}\")\n",
        "    print(\"Trying alternative installation...\")\n",
        "    !pip install xgboost optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A91IacE5MHOC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd #Pandas for data manipulation\n",
        "import numpy as np #Numpy for numerical computation\n",
        "import matplotlib.pyplot as plt #Matplotlib for data visualization\n",
        "import seaborn as sns #Seaborn for data visualization\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split, KFold #To split the dataset and initialize kfold\n",
        "from sklearn.metrics import mean_squared_error #For evaluation of mean_squared error\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder #For feature encoding of categorical data\n",
        "import xgboost as xgb #Model\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8UnivSnfgTw"
      },
      "source": [
        "LOADING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3S9sy_ZffyX"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/hackathon-qualification/archive/train.csv\") #Loading the train set\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/hackathon-qualification/archive/test.csv\") #Loading the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HtYi15Afmvr"
      },
      "outputs": [],
      "source": [
        "train_df.head(15) #To check the first 15 rows of the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOEHWjgQfxFp"
      },
      "outputs": [],
      "source": [
        "test_df.head(15) #To check the first 15 rows of the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JErRS3NJf4-2"
      },
      "outputs": [],
      "source": [
        "#Check the shape of the given datasets both train and test\n",
        "print(\"Train DataFrame Shape:\", train_df.shape)\n",
        "print(\"Test DataFrame Shape:\", test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfB8HReJgu6S"
      },
      "outputs": [],
      "source": [
        "train_df.describe() #To check the mathematical features of the numerical columns in the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhVeZnmrg3dV"
      },
      "outputs": [],
      "source": [
        "test_df.describe() #To check the mathematical features of the numerical columns in the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXeb-yWdg5L8"
      },
      "outputs": [],
      "source": [
        "train_df.info() #To check the information of the columns in the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hlo_QH0fg_sX"
      },
      "outputs": [],
      "source": [
        "test_df.info() #To check the information of the columns in the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLORATORY DATA ANALYSIS"
      ],
      "metadata": {
        "id": "KDRTFBmTgisT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqDZirgWhCaA"
      },
      "outputs": [],
      "source": [
        "print(\"DATA QUALITY ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "#Missing Values Analysis\n",
        "#Missing Values Analysis I Train set\n",
        "print(\"MISSING VALUES IN TRAINING DATA:\")\n",
        "missing_train = train_df.isnull().sum()\n",
        "print(missing_train[missing_train > 0])\n",
        "\n",
        "#Missing Values Analysis in Test set\n",
        "print(\"\\n2. MISSING VALUES IN TEST DATA:\")\n",
        "missing_test = test_df.isnull().sum()\n",
        "print(missing_test[missing_test > 0])\n",
        "\n",
        "#Target Variable Analysis\n",
        "print(\"\\n3. TARGET VARIABLE 'price' ANALYSIS:\")\n",
        "print(f\"   Min price: ${train_df['price'].min():,}\")\n",
        "print(f\"   Max price: ${train_df['price'].max():,}\")\n",
        "print(f\"   Mean price: ${train_df['price'].mean():,.0f}\")\n",
        "print(f\"   Median price: ${train_df['price'].median():,.0f}\")\n",
        "\n",
        "#Unique Values in Categorical Columns\n",
        "print(\"\\n4. CATEGORICAL FEATURES UNIQUE COUNTS:\")\n",
        "categorical_cols = train_df.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    print(f\"   {col}: {train_df[col].nunique()} unique values\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA VISUALIZATION"
      ],
      "metadata": {
        "id": "ijZxR1CRhp-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set style for plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "#Histograms for numerical features\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot histogram for model_year\n",
        "sns.histplot(train_df['model_year'], bins=20, ax=axes[0])\n",
        "axes[0].set_title('Distribution of Model Year')\n",
        "\n",
        "# Plot histogram for mileage\n",
        "sns.histplot(train_df['milage'], bins=20, ax=axes[1])\n",
        "axes[1].set_title('Distribution of Milage')\n",
        "\n",
        "# Plot histogram for price\n",
        "sns.histplot(train_df['price'], bins=20, ax=axes[2])\n",
        "axes[2].set_title('Distribution of Price')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "omP51eJjhso9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scatter plots vs price\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "#Scatter: model_year vs price\n",
        "sns.scatterplot(x=train_df['model_year'], y=train_df['price'], alpha=0.5, ax=axes[0])\n",
        "axes[0].set_title('Model Year vs Price')\n",
        "\n",
        "#Scatter: mileage vs price\n",
        "sns.scatterplot(x=train_df['milage'], y=train_df['price'], alpha=0.5, ax=axes[1])\n",
        "axes[1].set_title('Milage vs Price')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "PXFCdPlOiKf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation heatmap for numerical features\n",
        "numerical_df = train_df[['model_year', 'milage', 'price']]\n",
        "corr_matrix = numerical_df.corr()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Heatmap for Numerical Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jcA9ywRjiLME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create boxplots for numerical features\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "#Boxplot for price\n",
        "sns.boxplot(y=train_df['price'], ax=axes[0])\n",
        "axes[0].set_title('Boxplot of Price')\n",
        "\n",
        "# Boxplot for mileage\n",
        "sns.boxplot(y=train_df['milage'], ax=axes[1])\n",
        "axes[1].set_title('Boxplot of Mileage')\n",
        "\n",
        "# Boxplot for model_year\n",
        "sns.boxplot(y=train_df['model_year'], ax=axes[2])\n",
        "axes[2].set_title('Boxplot of Model Year')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ammfn3ZYiP8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to detect outliers using IQR\n",
        "def count_outliers(series):\n",
        "    Q1 = series.quantile(0.25)\n",
        "    Q3 = series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = series[(series < lower_bound) | (series > upper_bound)]\n",
        "    return len(outliers)\n",
        "\n",
        "# Count outliers for price and mileage\n",
        "price_outliers = count_outliers(train_df['price'])\n",
        "milage_outliers = count_outliers(train_df['milage'])\n",
        "\n",
        "print(f\"Number of outliers in price: {price_outliers}\")\n",
        "print(f\"Number of outliers in mileage: {milage_outliers}\")"
      ],
      "metadata": {
        "id": "0kBJD1HSiS7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import skew\n",
        "\n",
        "price_skew = skew(train_df['price']) #For evaluation of skewness\n",
        "print(f\"Skewness of price after cleaning: {price_skew}\")"
      ],
      "metadata": {
        "id": "Kk1VS9aEiV1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean price for each brand\n",
        "mean_price_by_brand = train_df.groupby('brand')['price'].mean().sort_values(ascending=False)\n",
        "\n",
        "#Top 10 brands by mean price\n",
        "top10_mean_price = mean_price_by_brand.head(10)\n",
        "\n",
        "# Bar plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=top10_mean_price.index, y=top10_mean_price.values)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Top 10 Brands by Average Price')\n",
        "plt.ylabel('Average Price ($)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NYbRIPJqibp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get count and mean price for top 10 brands by count\n",
        "top10_brands_by_count = train_df['brand'].value_counts().head(10).index\n",
        "train_top10 = train_df[train_df['brand'].isin(top10_brands_by_count)]\n",
        "\n",
        "# Bar plot: mean price for top 10 brands (by count)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='brand', y='price', data=train_top10, estimator='mean')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Average Price for Top 10 Brands (by Frequency)')\n",
        "plt.ylabel('Average Price ($)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rxj4ZYL7if76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fuel_type vs mean price\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x='fuel_type', y='price', data=train_df, estimator='mean')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Average Price by Fuel Type')\n",
        "plt.show()\n",
        "\n",
        "# Accident vs mean price\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x='accident', y='price', data=train_df, estimator='mean')\n",
        "plt.title('Average Price by Accident History')\n",
        "plt.show()\n",
        "\n",
        "# Transmission vs mean price (top 10 common transmissions)\n",
        "top_transmissions = train_df['transmission'].value_counts().head(10).index\n",
        "train_top_trans = train_df[train_df['transmission'].isin(top_transmissions)]\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.barplot(x='transmission', y='price', data=train_top_trans, estimator='mean')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Average Price by Top 10 Transmissions')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gJGMn6nDiilH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA CLEANING"
      ],
      "metadata": {
        "id": "MnMF4Uyigzlp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NamWbQpDsv5B"
      },
      "outputs": [],
      "source": [
        "print(\" SMART DATA CLEANING\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "#Remove extreme price outliers (99.9th percentile)\n",
        "price_upper_limit = train_df['price'].quantile(0.999)\n",
        "train_clean = train_df[train_df['price'] <= price_upper_limit].copy()\n",
        "outliers_removed = len(train_df) - len(train_clean)\n",
        "\n",
        "print(f\"1. Removed {outliers_removed} extreme price outliers\")\n",
        "print(f\"   Price upper limit: ${price_upper_limit:,.0f}\")\n",
        "\n",
        "#Drop useless clean_title column (only 1 value)\n",
        "train_clean = train_clean.drop('clean_title', axis=1)\n",
        "test_df = test_df.drop('clean_title', axis=1)\n",
        "\n",
        "print(\"2. Dropped 'clean_title' column (only 1 unique value)\")\n",
        "\n",
        "#Handle missing values\n",
        "print(\"3. Missing values to handle later:\")\n",
        "print(f\"   - fuel_type: {train_clean['fuel_type'].isnull().sum()} missing\")\n",
        "print(f\"   - accident: {train_clean['accident'].isnull().sum()} missing\")\n",
        "\n",
        "print(f\"\\nNew training shape: {train_clean.shape}\")\n",
        "print(f\" New test shape: {test_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Strategic Missing Value Handling"
      ],
      "metadata": {
        "id": "diN6BvRIg90J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "essCzkWHs_vn"
      },
      "outputs": [],
      "source": [
        "print(\" SMART MISSING VALUE HANDLING\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "#Handle fuel_type missing values - use mode but be smart\n",
        "most_common_fuel = train_clean['fuel_type'].mode()[0]\n",
        "train_clean['fuel_type'] = train_clean['fuel_type'].fillna(most_common_fuel)\n",
        "test_df['fuel_type'] = test_df['fuel_type'].fillna(most_common_fuel)\n",
        "\n",
        "print(f\"1. Filled fuel_type missing values with: '{most_common_fuel}'\")\n",
        "\n",
        "#Handle accident missing values - use 'None reported' (most common)\n",
        "train_clean['accident'] = train_clean['accident'].fillna('None reported')\n",
        "test_df['accident'] = test_df['accident'].fillna('None reported')\n",
        "\n",
        "print(\"2. Filled accident missing values with: 'None reported'\")\n",
        "\n",
        "#Verify no more missing values\n",
        "print(\"\\n MISSING VALUES AFTER HANDLING:\")\n",
        "print(\"Training data:\")\n",
        "print(train_clean.isnull().sum())\n",
        "print(\"\\nTest data:\")\n",
        "print(test_df.isnull().sum())\n",
        "\n",
        "print(f\"\\n FINAL CLEAN DATA SHAPES:\")\n",
        "print(f\"Training: {train_clean.shape}\")\n",
        "print(f\"Test: {test_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEATURE ENCODING"
      ],
      "metadata": {
        "id": "SUoRehvEhHyp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DGH8BMrtP6i"
      },
      "outputs": [],
      "source": [
        "print(\" ADVANCED FEATURE ENGINEERING\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Create new features for both training and test data\n",
        "def create_features(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    #Car Age (current year - model_year)\n",
        "    df['car_age'] = 2025 - df['model_year']\n",
        "\n",
        "    #Mileage per Year (usage intensity)\n",
        "    df['miles_per_year'] = df['milage'] / df['car_age'].clip(lower=1)\n",
        "\n",
        "    #Luxury Brand Flag (premium brands)\n",
        "    luxury_brands = ['BMW', 'Mercedes-Benz', 'Audi', 'Lexus', 'Porsche', 'Genesis', 'Land Rover', 'Jaguar']\n",
        "    df['is_luxury'] = df['brand'].isin(luxury_brands).astype(int)\n",
        "\n",
        "    #Engine Power Extraction (if available in engine text)\n",
        "    df['has_turbo'] = df['engine'].str.contains('Turbo|Twin|Supercharger', case=False, na=False).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply to both datasets\n",
        "train_enhanced = create_features(train_clean)\n",
        "test_enhanced = create_features(test_df)\n",
        "\n",
        "print(\"CREATED POWERFUL NEW FEATURES:\")\n",
        "print(\"   - car_age (years since model year)\")\n",
        "print(\"   - miles_per_year (annual usage intensity)\")\n",
        "print(\"   - is_luxury (premium brand flag)\")\n",
        "print(\"   - has_turbo (high-performance engine flag)\")\n",
        "\n",
        "print(f\"\\n Enhanced Training Shape: {train_enhanced.shape}\")\n",
        "print(f\" Enhanced Test Shape: {test_enhanced.shape}\")\n",
        "\n",
        "print(\"\\n Sample of new features:\")\n",
        "display(train_enhanced[['brand', 'model_year', 'car_age', 'miles_per_year', 'is_luxury', 'has_turbo']].head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Prepare Data for Modeling"
      ],
      "metadata": {
        "id": "85MNfIJZhU-z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWUROfdRtgR9"
      },
      "outputs": [],
      "source": [
        "print(\" PREPARING DATA FOR MODELING\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "#Separate features (X) and target (y) for training\n",
        "X = train_enhanced.drop('price', axis=1)\n",
        "y = train_enhanced['price']\n",
        "\n",
        "print(\" FEATURES (X) and TARGET (y) separated:\")\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n",
        "\n",
        "#Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "print(f\"\\n Categorical features ({len(categorical_cols)}):\")\n",
        "print(categorical_cols)\n",
        "\n",
        "print(f\"\\n Numerical features ({len(numerical_cols)}):\")\n",
        "print(numerical_cols)\n",
        "\n",
        "print(f\"\\n New engineered features:\")\n",
        "new_features = ['car_age', 'miles_per_year', 'is_luxury', 'has_turbo']\n",
        "for feat in new_features:\n",
        "    print(f\"   - {feat}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove ID Column & Retrain on FULL DATA"
      ],
      "metadata": {
        "id": "sDhiw1vWivgo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwnlfSBtrnN_"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\" REMOVING PROBLEMATIC ID COLUMN & TRAINING ON FULL DATA\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Remove ID column from all datasets\n",
        "X_encoded_no_id = X_encoded.drop('id', axis=1)\n",
        "test_encoded_no_id = test_encoded.drop('id', axis=1)\n",
        "\n",
        "print(\" ID COLUMN REMOVED!\")\n",
        "print(f\"New X shape: {X_encoded_no_id.shape}\")\n",
        "print(f\"New test shape: {test_encoded_no_id.shape}\")\n",
        "\n",
        "# Train on FULL dataset (no splitting)\n",
        "print(\"\\n TRAINING XGBOOST ON FULL DATASET (NO SPLITTING)...\")\n",
        "\n",
        "xgb_model_full = xgb.XGBRegressor(\n",
        "    n_estimators=2500,\n",
        "    learning_rate=0.01,\n",
        "    max_depth=5,\n",
        "    subsample=0.6,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=0,\n",
        "    n_jobs=-1,\n",
        "    eval_metric='rmse'\n",
        ")\n",
        "\n",
        "# Train on ALL data (no validation split)\n",
        "xgb_model_full.fit(X_encoded_no_id, y, verbose=50)\n",
        "\n",
        "print(\"XGBOOST TRAINING COMPLETED ON FULL DATASET!\")\n",
        "\n",
        "#CREATE SUBMISSION\n",
        "print(\" CREATING SUBMISSION FILE\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Make predictions on the test set\n",
        "print(\"Making predictions on test data...\")\n",
        "test_predictions = xgb_model_full.predict(test_encoded_no_id)\n",
        "\n",
        "print(f\"Predictions range: ${test_predictions.min():,.2f} - ${test_predictions.max():,.2f}\")\n",
        "print(f\"Mean prediction: ${test_predictions.mean():,.2f}\")\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],  # Use the original ID column from test data\n",
        "    'price': test_predictions\n",
        "})\n",
        "\n",
        "# Save the submission file\n",
        "submission_file = 'submission_xgboost_full.csv'\n",
        "submission.to_csv(submission_file, index=False)\n",
        "print(f\"Submission saved as '{submission_file}'\")\n",
        "\n",
        "# Verify the submission\n",
        "print(f\"Submission shape: {submission.shape}\")\n",
        "print(f\" Number of predictions: {len(submission)}\")\n",
        "\n",
        "print(f\"\\n SUBMISSION READY: {submission_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ESTIMATE RMSE USING TRAINING DATA\n",
        "print(\" ESTIMATING RMSE\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Make predictions on the training data\n",
        "train_predictions = xgb_model_full.predict(X_encoded_no_id)\n",
        "\n",
        "# Calculate RMSE on training data\n",
        "train_rmse = np.sqrt(mean_squared_error(y, train_predictions))\n",
        "\n",
        "print(f\"Training RMSE: ${train_rmse:,.2f}\")\n",
        "\n",
        "# This gives you an estimate of how well your model performs\n",
        "# Note: This will usually be optimistic (lower than actual test RMSE)\n",
        "# A good rule of thumb is to add 5-15% to this estimate for test performance\n",
        "\n",
        "estimated_test_rmse = train_rmse * 1.1  # Add 10% buffer\n",
        "print(f\"Estimated Test RMSE: ${estimated_test_rmse:,.2f} (with 10% buffer)\")\n",
        "\n",
        "# ADDITIONAL PERFORMANCE METRICS\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "train_mae = mean_absolute_error(y, train_predictions)\n",
        "train_r2 = r2_score(y, train_predictions)\n",
        "\n",
        "print(f\"Training MAE: ${train_mae:,.2f}\")\n",
        "print(f\"Training R²: {train_r2:.4f}\")\n",
        "\n",
        "#ANALYZE PREDICTION ACCURACY\n",
        "print(\"\\n PREDICTION ACCURACY ANALYSIS:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Calculate error statistics\n",
        "errors = y - train_predictions\n",
        "abs_errors = np.abs(errors)\n",
        "\n",
        "print(f\"Mean Error: ${errors.mean():,.2f}\")\n",
        "print(f\"Mean Absolute Error: ${abs_errors.mean():,.2f}\")\n",
        "print(f\"Max Overprediction: ${errors.min():,.2f}\")\n",
        "print(f\"Max Underprediction: ${errors.max():,.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "amQ_Jjs5jIa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zFqFzrUIjSAG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsl+xNQcdIynpPvDsemMOo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}